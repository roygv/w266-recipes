{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roy Gvirtsman <roy.gvirtsman@berkeley.edu>\n",
    "\n",
    "Chuqing He <chqngh@berkeley.edu> \n",
    "\n",
    "Tony Panza <apanza@berkeley.edu>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "This shall examine vector representations of cooking recipes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "A similar work and idea for inspiration is the Stanford CS224n paper by Agarwal and Miller (2011)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Data Acquisition\n",
    "\n",
    "Scrapy was used to crawl and scrape all of the recipe data from allrecipes.com into JSON format. To keep the JSON file sizes reasonably small, the scraping was divided into 1 or 2 categories at a time. All of the JSON files were then uploaded into an Amazon AWS S3 bucket. So far, we have accumulated over 100,000 recipes, and they consist of 167 MB of JSON data.\n",
    "\n",
    "## Data Processing and Ingredient Extraction - Brute Force\n",
    "\n",
    "For initial development purposes, only one JSON file (consisting of two categories from allrecipes.com) was loaded into a Pandas dataframe. (Ultimately, all of the JSON files will need to be loaded into a common data frame.)\n",
    "\n",
    "An example of the `ingredients` column from one of the rows looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'3/4 cup sweetened dried cranberries, chopped',\n",
       " u'1 McIntosh apple - peeled, cored, and diced',\n",
       " u'1/2 small red onion, finely chopped',\n",
       " u'2 tablespoons lemon juice',\n",
       " u'2 teaspoons honey',\n",
       " u'1 teaspoon chili powder',\n",
       " u'1/2 teaspoon ground cinnamon',\n",
       " u'1 (6 ounce) bag baby spinach, torn into bite-sized pieces',\n",
       " u'Add all ingredients to list',\n",
       " u'Add all ingredients to list']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u'3/4 cup sweetened dried cranberries, chopped',\n",
    " u'1 McIntosh apple - peeled, cored, and diced',\n",
    " u'1/2 small red onion, finely chopped',\n",
    " u'2 tablespoons lemon juice',\n",
    " u'2 teaspoons honey',\n",
    " u'1 teaspoon chili powder',\n",
    " u'1/2 teaspoon ground cinnamon',\n",
    " u'1 (6 ounce) bag baby spinach, torn into bite-sized pieces',\n",
    " u'Add all ingredients to list',\n",
    " u'Add all ingredients to list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Ingredient Vocabulary\n",
    "\n",
    "Each row of the dataframe was run through a function to extract the core ingredients by removing the measurement numbers, units, and descriptions. This was (for now) just done through the use of lookup table to remove unwanted words. The unwanted words are organized into three categories: measurement units, preparatory descriptions, and miscellaneous. Example measurement units are: `cups`, `pounds`, `liters`, `boxes`, and `halves`. Example preparatory descriptions are: `crumbled`, `peeled`, and `thawed`. Example miscellaneous words are: `about`, `thinly`, and `more`. Non-letter characters were also removed. These lookup tables were developed through some domain knowledge and by spot checking random recipes. We hope to improve this by migrating to a more robust method such as a part of speech tagger (see below)\n",
    "\n",
    "The example ingredient list shown above was \"cleaned\" to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sweetened cranberries',\n",
       " u'mcintosh apple',\n",
       " u'red onion',\n",
       " u'lemon juice',\n",
       " u'honey',\n",
       " u'chili powder',\n",
       " u'cinnamon',\n",
       " u'baby spinach']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[u'sweetened cranberries',\n",
    " u'mcintosh apple',\n",
    " u'red onion',\n",
    " u'lemon juice',\n",
    " u'honey',\n",
    " u'chili powder',\n",
    " u'cinnamon',\n",
    " u'baby spinach']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a list of all the unique ingredients from the entire data frame, the cleaned lists from each recipe were flattened into one big list with `np.hstack`, then unique items identified with `set()` function. From this, we have our \"vocabulary\" of ingredients.\n",
    "\n",
    "## Vectorized Recipes\n",
    "\n",
    "Sklearn's `CountVectorizer` was used to construct a sparse matrix of recipes down the rows and ingredients along the columns. The unique vocabulary for ingredients processing is passed in as the `vocabulary` argument.\n",
    "\n",
    "Then sklearn's `TruncatedSVD` was used to reduce the dimensionality of the recipe-ingredient matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also did a simple ingredients clustering on our two JSON categories, appetizers_salads and bbq_bread. The preprocessing step is similar to building the vocabulary step. The KMeans pipeline consist of CountVectorizer, TFIDFTransformer, and KMeans Classifier. We used the categories as the true labels and clustered on 2 centroids. The metrics report is as following:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "'''\n",
    "            Precision    Recall  F1-Score     \n",
    "   bbqbread     0.57         0.92     0.70       \n",
    "   \n",
    "     salads     0.97         0.78     0.86     \n",
    "     \n",
    "avg / total     0.87         0.81     0.82       \n",
    "'''\n",
    "#\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also found the top 10 Words in each cluster:   \n",
    "  \n",
    "\n",
    "Top terms per cluster:  \n",
    "Cluster 0 (salads):  \n",
    " pepper,\n",
    " cheese,\n",
    " garlic,\n",
    " salt,\n",
    " black,\n",
    " oil,\n",
    " onion,\n",
    " red,\n",
    " sauce,\n",
    " green\n",
    "  \n",
    "Cluster 1(bbqbread):  \n",
    " flour,\n",
    " baking,\n",
    " sugar,\n",
    " allpurpose,\n",
    " white,\n",
    " milk,\n",
    " butter,\n",
    " powder,\n",
    " salt,\n",
    " eggs,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, further work can and will be done to enhance the model. We hope to be able to take in a set of ingredients and classify the category most likely associated with those ingredients, which could be a method of identifying the recipe's categories.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Discussion\n",
    "\n",
    "Another approach we intend to explore is how similar to one another are recipes with a common word in the title. For example, given a recipe with \"chili\" in the title, what is the cosine distance to the next closest chili recipe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "Try the [Google part of speech parser](https://cloud.google.com/natural-language/) as a way to extract and identify the \"core\" ingredients from an ingredients list.\n",
    "\n",
    "![Example tagging of ingredients](pasted_image_at_2017_07_25_11_38_pm.png)\n",
    "\n",
    "This would hopefully generalize better than using a lookup table to remove words known to not be of interest.\n",
    "\n",
    "We also need to do some experimentation and analysis of the optimal `n_components` used for SVD for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Jaan Altosaar. 2017. food2vec - Augmented cooking with machine intelligence – Jaan Altosaar.\n",
    "\n",
    "Rahul Agarwal and Kevin Miller. 2011. Information Extraction from Recipes. Technical report.\n",
    "\n",
    "Tiago Simas, Michal Ficek, Albert Diaz-Guilera, Pere Obrador and Pablo R. Rodriguez. 2017. Food-Bridging: A New Network Construction to Unveil the Principles of Cooking. Frontiers in ICT, 4.\n",
    "\n",
    "Wesley Tansey, Edward Lowe and James Scott. 2016. _Diet2Vec: Multi-scale analysis of massive dietary data_. 1st edition.\n",
    "\n",
    "Yong-Yeol Ahn, Sebastian E. Ahnert, James P. Bagrow and Albert-László Barabási. 2011. Flavor network and the principles of food pairing. _Scientific Reports_, 1(1)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
