{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from tqdm import tqdm as ProgressBar\n",
    "import six # needed for Google Cloud client\n",
    "import operator\n",
    "import sys\n",
    "import en # NodeBox https://www.nodebox.net/code/index.php/Linguistics#verb_conjugation\n",
    "from nltk.corpus import stopwords\n",
    "import parsing_util\n",
    "import pickle\n",
    "\n",
    "from google.cloud import language\n",
    "from google.cloud.language import enums\n",
    "from google.cloud.language import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48417, 11)\n",
      "[ [u'In a bowl, mix the tomatoes, onion, red bell pepper, yellow bell pepper, cilantro, lime juice, and salt. Cover and refrigerate until ready to serve.']]\n",
      "[ [u'6 roma (plum) tomatoes, diced', u'1 sweet onion, diced', u'1 medium red bell pepper, diced', u'1 medium yellow bell pepper, diced', u'1 bunch cilantro, finely minced', u'1 lime, juiced', u'1 teaspoon salt, or to taste', u'Add all ingredients to list', u'Add all ingredients to list']]\n",
      "[ ['roma plum tomatoes', 'sweet onion', 'red bell pepper', 'yellow bell pepper', 'cilantro', 'lime', 'salt']]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_pickle('CleanedIngredients.pkl')\n",
    "df.drop_duplicates(subset='url', keep='first', inplace=True)\n",
    "print df.shape\n",
    "print df[['instructionSteps']].values[0]\n",
    "print df[['ingredients']].values[0]\n",
    "print df[['cleanedIngredients']].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a list of stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "stopVerbs = {'bring','make'} # These are useless verbs that should be ignored\n",
    "goVerbs = {'preheat'}  # These are verbs that are often not recognized as such\n",
    "\n",
    "\n",
    "def get_verbs(parsedInstructions, Ingredients, ingredientsDict, debug=0):\n",
    "\n",
    "    tokens = parsedInstructions\n",
    "\n",
    "    # part-of-speech tags from enums.PartOfSpeech.Tag\n",
    "    pos_tag = ('UNKNOWN', 'ADJ', 'ADP', 'ADV', 'CONJ', 'DET', 'NOUN', 'NUM',\n",
    "               'PRON', 'PRT', 'PUNCT', 'VERB', 'X', 'AFFIX')\n",
    "    idx=0\n",
    "    verbs=list()\n",
    "    for token in tokens:\n",
    "        tag = pos_tag[token.part_of_speech.tag]\n",
    "        if token.text.content.lower() != token.text.content and en.is_verb(token.text.content.lower()):\n",
    "            tag = 'VERB'\n",
    "        # If this was identified and a noun and can be a verb and there is a noun following\n",
    "        elif (tag == 'NOUN' # parser thinks it is a NOUN but can also be a verb\n",
    "             and len(tokens) > idx+1\n",
    "             and en.is_verb(token.text.content.lower()) and pos_tag[tokens[idx+1].part_of_speech.tag] == 'NOUN'):\n",
    "            if (pos_tag[tokens[idx-1].part_of_speech.tag] == 'PUNCT') and token.text.content not in ingredientsDict:\n",
    "                tag = 'VERB'\n",
    "        else:\n",
    "            tag = pos_tag[token.part_of_speech.tag]\n",
    "\n",
    "        if pos_tag[token.part_of_speech.tag] == 'VERB':\n",
    "            verb=(token.text.content).lower()\n",
    "            #try:        \n",
    "            #    verb=en.verb.present(verb)\n",
    "            #except:\n",
    "            #    pass\n",
    "            if verb not in stopWords and verb not in stopVerbs:\n",
    "                verbs.append(verb)\n",
    "        if pos_tag[token.part_of_speech.tag] == 'VERB':\n",
    "            verb=(token.text.content).lower()\n",
    "            if verb in goVerbs:\n",
    "                verbs.append(verb)\n",
    "            \n",
    "        if debug > 5:\n",
    "            print(u'{}: {}'.format(pos_tag[token.part_of_speech.tag], token.text.content.lower()))\n",
    "        idx += 1\n",
    "    return(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recipes: 48417it [03:31, 229.38it/s]\n"
     ]
    }
   ],
   "source": [
    "verbsDict=defaultdict(int)\n",
    "insDict = parsing_util.Instructions()  \n",
    "cleanedIngredientsDict=pd.read_pickle('cleanerIngredients.pkl')  \n",
    "added=0\n",
    "#for idx,row in df.sample(1).iterrows():\n",
    "for idx, row in ProgressBar(df.iterrows(), desc=\"Processing recipes\"):\n",
    "    url=row[\"url\"]\n",
    "    # print url\n",
    "    parsedInstructions=insDict.parse(url,row[\"instructionSteps\"])\n",
    "    Ingredients=cleanedIngredientsDict.get(url,[])\n",
    "    verbs=get_verbs(parsedInstructions, Ingredients, verbsDict, debug=0)\n",
    "    verbsDict[url] = verbs\n",
    "    #for verb in verbs:\n",
    "    #    verbsDict[verb] += 1\n",
    "        # print verb\n",
    "    added+=1\n",
    "    if added > 10000:\n",
    "        with open('verbs.pkl', 'wb') as f:\n",
    "            pickle.dump(verbsDict, f) \n",
    "        added = 0\n",
    "    \n",
    "with open('verbs.pkl', 'wb') as f:\n",
    "    pickle.dump(verbsDict, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "965"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allVerbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#verbVertor =  [get_verbs('.'.join(df[['instructionSteps']].values[i][0])) for i in range(df.shape[0])]\n",
    "#df['verbs']=verbVertor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
